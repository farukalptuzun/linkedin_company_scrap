# LinkedIn Åirket Verisi Ã‡ekme Sistemi - DetaylÄ± Analiz Raporu

## ğŸ“‹ Ä°Ã§indekiler

1. [Proje Genel BakÄ±ÅŸ](#proje-genel-bakÄ±ÅŸ)
2. [Proje YapÄ±sÄ±](#proje-yapÄ±sÄ±)
3. [Sistem NasÄ±l Ã‡alÄ±ÅŸÄ±yor?](#sistem-nasÄ±l-Ã§alÄ±ÅŸÄ±yor)
4. [Spider'larÄ±n DetaylÄ± Analizi](#spiderlarÄ±n-detaylÄ±-analizi)
5. [Ã‡ekilen Veriler](#Ã§ekilen-veriler)
6. [Gereksinimler ve Kurulum](#gereksinimler-ve-kurulum)
7. [KullanÄ±m KÄ±lavuzu](#kullanÄ±m-kÄ±lavuzu)
8. [Teknik Detaylar](#teknik-detaylar)
9. [Ã–nemli Notlar ve SÄ±nÄ±rlamalar](#Ã¶nemli-notlar-ve-sÄ±nÄ±rlamalar)

---

## ğŸ¯ Proje Genel BakÄ±ÅŸ

Bu proje, LinkedIn platformundan ÅŸirket verilerini otomatik olarak Ã§ekmek iÃ§in geliÅŸtirilmiÅŸ bir **Scrapy** tabanlÄ± web scraping sistemidir. Sistem, iki aÅŸamalÄ± bir yaklaÅŸÄ±m kullanarak:

1. **Ä°lk AÅŸama**: LinkedIn ÅŸirket dizininden binlerce ÅŸirket ismi ve URL'lerini toplar
2. **Ä°kinci AÅŸama**: BelirttiÄŸiniz ÅŸirketlerin detaylÄ± profil bilgilerini Ã§eker

### Projenin AmacÄ±
- LinkedIn'deki ÅŸirket dizininden toplu veri Ã§ekme
- Belirli ÅŸirketlerin detaylÄ± profil bilgilerini otomatik olarak toplama
- AraÅŸtÄ±rma, analiz ve iÅŸ geliÅŸtirme amaÃ§lÄ± veri toplama

---

## ğŸ“ Proje YapÄ±sÄ±

```
LinkedIn-Company-Data-Scraping-System/
â”œâ”€â”€ company_data_scraper/              # Ana proje klasÃ¶rÃ¼
â”‚   â”œâ”€â”€ company_data_scraper/          # Scrapy proje modÃ¼lÃ¼
â”‚   â”‚   â”œâ”€â”€ spiders/                   # Spider'lar (veri Ã§ekme botlarÄ±)
â”‚   â”‚   â”‚   â”œâ”€â”€ linkedin_directory_scraper.py    # Åirket dizini Ã§ekici
â”‚   â”‚   â”‚   â””â”€â”€ company_profile_scraper.py       # Åirket profil Ã§ekici
â”‚   â”‚   â”œâ”€â”€ items.py                   # Veri modelleri (ÅŸu an kullanÄ±lmÄ±yor)
â”‚   â”‚   â”œâ”€â”€ pipelines.py               # Veri iÅŸleme pipeline'larÄ±
â”‚   â”‚   â”œâ”€â”€ middlewares.py             # Middleware'ler (istek/yanÄ±t iÅŸleme)
â”‚   â”‚   â”œâ”€â”€ settings.py                # Scrapy ayarlarÄ±
â”‚   â”‚   â””â”€â”€ __init__.py
â”‚   â”œâ”€â”€ scrapy.cfg                     # Scrapy konfigÃ¼rasyon dosyasÄ±
â”‚   â”œâ”€â”€ directorydata.json             # Ã‡ekilen ÅŸirket dizini verileri (198K+ satÄ±r)
â”‚   â””â”€â”€ company_profile.json           # Ã‡ekilen ÅŸirket profil verileri
â”œâ”€â”€ README.md                           # Ä°ngilizce dokÃ¼mantasyon
â””â”€â”€ LICENSE                             # Lisans dosyasÄ±
```

---

## âš™ï¸ Sistem NasÄ±l Ã‡alÄ±ÅŸÄ±yor?

### Genel Ã‡alÄ±ÅŸma MantÄ±ÄŸÄ±

Proje, **iki ayrÄ± spider** kullanarak Ã§alÄ±ÅŸÄ±r:

#### 1ï¸âƒ£ LinkedIn Directory Scraper (Dizin Ã‡ekici)
- LinkedIn'in ÅŸirket dizin sayfasÄ±nÄ± tarar
- Google Cache Ã¼zerinden eriÅŸim saÄŸlar (anti-bot korumasÄ±nÄ± aÅŸmak iÃ§in)
- A'dan Z'ye tÃ¼m harfler iÃ§in dizin sayfalarÄ±nÄ± ziyaret eder
- Her sayfadaki ÅŸirket isimlerini ve LinkedIn URL'lerini toplar
- SonuÃ§larÄ± `directorydata.json` dosyasÄ±na kaydeder

#### 2ï¸âƒ£ Company Profile Scraper (Profil Ã‡ekici)
- `directorydata.json` dosyasÄ±nÄ± okur
- KullanÄ±cÄ±nÄ±n belirttiÄŸi ÅŸirket isimlerini arar
- Bulunan ÅŸirketlerin LinkedIn URL'lerini alÄ±r
- Her ÅŸirket profil sayfasÄ±nÄ± ziyaret eder
- DetaylÄ± ÅŸirket bilgilerini Ã§Ä±karÄ±r
- SonuÃ§larÄ± `company_profile.json` dosyasÄ±na kaydeder

### Veri AkÄ±ÅŸÄ±

```
LinkedIn Dizin SayfasÄ±
    â†“
[linkedin_directory_scraper.py]
    â†“
directorydata.json (Åirket Ä°simleri + URL'ler)
    â†“
[company_profile_scraper.py]
    â†“
company_profile.json (DetaylÄ± Åirket Bilgileri)
```

---

## ğŸ•·ï¸ Spider'larÄ±n DetaylÄ± Analizi

### 1. LinkedIn Directory Scraper (`linkedin_directory_scraper.py`)

#### Ne Yapar?
LinkedIn'in ÅŸirket dizininden tÃ¼m ÅŸirket isimlerini ve URL'lerini toplar.

#### NasÄ±l Ã‡alÄ±ÅŸÄ±r?

**BaÅŸlangÄ±Ã§ URL'leri:**
- Ana dizin sayfasÄ±: `https://webcache.googleusercontent.com/search?q=cache:https://www.linkedin.com/directory/companies`
- A-Z harfleri iÃ§in 26 farklÄ± sayfa
- "More" kategorisi iÃ§in ek bir sayfa
- **Toplam 27 farklÄ± sayfa** taranÄ±r

**Ã‡alÄ±ÅŸma AdÄ±mlarÄ±:**

1. **Ä°lk Parse (`parse` metodu):**
   - Ana sayfadaki Ã¶ne Ã§Ä±kan ÅŸirketleri (`featured_company_listings`) Ã§eker
   - Åirket isimlerini ve URL'lerini bir dictionary'ye kaydeder
   - Ä°lk harf sayfasÄ±na (A harfi) geÃ§iÅŸ yapar

2. **Harf SayfalarÄ±nÄ± Parse Etme (`parse_response` metodu):**
   - Her harf iÃ§in (A, B, C, ..., Z, More) sayfayÄ± ziyaret eder
   - Sayfadaki tÃ¼m ÅŸirket listelerini (`listings__entry-link`) Ã§eker
   - Åirket ismi â†’ URL eÅŸleÅŸtirmesi yapar
   - Bir sonraki harf sayfasÄ±na geÃ§er

**Ã‡Ä±ktÄ± FormatÄ±:**
```json
[
    {
        "Amazon": "https://www.linkedin.com/company/amazon?trk=companies_directory",
        "Google": "https://www.linkedin.com/company/google?trk=companies_directory",
        "Microsoft": "https://www.linkedin.com/company/microsoft?trk=companies_directory",
        ...
    }
]
```

**Ã–nemli Notlar:**
- Google Cache kullanÄ±lÄ±yor (LinkedIn'in doÄŸrudan eriÅŸimini engellemek iÃ§in)
- YaklaÅŸÄ±k **200,000+ ÅŸirket** verisi Ã§ekilebilir
- Her harf iÃ§in ayrÄ± sayfa ziyaret edilir

---

### 2. Company Profile Scraper (`company_profile_scraper.py`)

#### Ne Yapar?
BelirttiÄŸiniz ÅŸirketlerin detaylÄ± profil bilgilerini Ã§eker.

#### NasÄ±l Ã‡alÄ±ÅŸÄ±r?

**BaÅŸlangÄ±Ã§ AyarlarÄ±:**
```python
desired_company_names = ["OpenAI", "Microsoft"]  # Ä°stediÄŸiniz ÅŸirketleri buraya ekleyin
input_file = 'directorydata.json'  # Åirket URL'lerinin bulunduÄŸu dosya
```

**Ã‡alÄ±ÅŸma AdÄ±mlarÄ±:**

1. **URL Bulma (`get_url_by_company_name` fonksiyonu):**
   - `directorydata.json` dosyasÄ±nÄ± okur
   - `desired_company_names` listesindeki ÅŸirketleri arar
   - Bulunan ÅŸirketlerin LinkedIn URL'lerini toplar
   - EÄŸer ÅŸirket bulunamazsa hata verir

2. **Profil SayfalarÄ±nÄ± Ziyaret Etme (`start_requests` metodu):**
   - Bulunan URL'lerden ilkini alÄ±r
   - Scrapy Request oluÅŸturur ve parse iÅŸlemini baÅŸlatÄ±r

3. **Veri Ã‡Ä±karma (`parse_response` metodu):**
   - Her ÅŸirket profil sayfasÄ±ndan **16 farklÄ± veri** Ã§Ä±karÄ±r:
     - Åirket adÄ±
     - LinkedIn takipÃ§i sayÄ±sÄ±
     - Åirket logosu URL'i
     - HakkÄ±nda bÃ¶lÃ¼mÃ¼
     - Ã‡alÄ±ÅŸan sayÄ±sÄ±
     - Web sitesi
     - SektÃ¶r
     - Åirket bÃ¼yÃ¼klÃ¼ÄŸÃ¼
     - Genel merkez konumu
     - Åirket tipi
     - KuruluÅŸ yÄ±lÄ±
     - UzmanlÄ±k alanlarÄ±
     - Fonlama bilgileri
     - Toplam fonlama turu sayÄ±sÄ±
     - Fonlama seÃ§eneÄŸi
     - Son fonlama turu tarihi

**Ã‡Ä±ktÄ± FormatÄ±:**
```json
[
    {
        "company_name": "OpenAI",
        "linkedin_followers_count": 2610704,
        "company_logo_url": "https://media.licdn.com/...",
        "about_us": "OpenAI is an AI research...",
        "num_of_employees": 1230,
        "website": "https://openai.com/",
        "industry": "Research Services",
        "company_size_approx": "201-500",
        "headquarters": "San Francisco, CA",
        "type": "Partnership",
        "founded": "2015",
        "specialties": "artificial intelligence and machine learning",
        "funding": "not-found",
        "funding_total_rounds": 10,
        "funding_option": "Secondary market",
        "last_funding_round": "Sep 14, 2023"
    }
]
```

**CSS/XPath SeÃ§icileri:**
- Åirket adÄ±: `.top-card-layout__entity-info h1`
- TakipÃ§i sayÄ±sÄ±: XPath ile `//h3[contains(@class, "top-card-layout__first-subline")]`
- Logo: `div.top-card-layout__entity-image-container img::attr(data-delayed-url)`
- HakkÄ±nda: `.core-section-container__content p`
- Detaylar: `.core-section-container__content .mb-2` (Ã§oklu element)

---

## ğŸ“Š Ã‡ekilen Veriler

### Directory Scraper'dan Gelen Veriler

| Veri Tipi | AÃ§Ä±klama | Ã–rnek |
|-----------|----------|-------|
| Åirket Ä°smi | LinkedIn'deki ÅŸirket adÄ± | "Microsoft" |
| LinkedIn URL | Åirketin LinkedIn profil sayfasÄ± URL'i | "https://www.linkedin.com/company/microsoft" |

**Toplam Veri MiktarÄ±:** ~200,000 ÅŸirket

---

### Profile Scraper'dan Gelen Veriler

| # | Veri AlanÄ± | AÃ§Ä±klama | Veri Tipi | Ã–rnek DeÄŸer |
|---|------------|----------|-----------|-------------|
| 1 | `company_name` | Åirketin resmi adÄ± | String | "OpenAI" |
| 2 | `linkedin_followers_count` | LinkedIn'deki takipÃ§i sayÄ±sÄ± | Integer | 2610704 |
| 3 | `company_logo_url` | Åirket logosunun URL'i | String | "https://media.licdn.com/..." |
| 4 | `about_us` | Åirket hakkÄ±nda aÃ§Ä±klama metni | String | "OpenAI is an AI research..." |
| 5 | `num_of_employees` | Ã‡alÄ±ÅŸan sayÄ±sÄ± | Integer/String | 1230 |
| 6 | `website` | Åirketin resmi web sitesi | String | "https://openai.com/" |
| 7 | `industry` | SektÃ¶r bilgisi | String | "Research Services" |
| 8 | `company_size_approx` | Åirket bÃ¼yÃ¼klÃ¼ÄŸÃ¼ aralÄ±ÄŸÄ± | String | "201-500" |
| 9 | `headquarters` | Genel merkez konumu | String | "San Francisco, CA" |
| 10 | `type` | Åirket tipi | String | "Partnership" |
| 11 | `founded` | KuruluÅŸ yÄ±lÄ± | String | "2015" |
| 12 | `specialties` | UzmanlÄ±k alanlarÄ± | String | "artificial intelligence..." |
| 13 | `funding` | Fonlama bilgisi | String | "not-found" |
| 14 | `funding_total_rounds` | Toplam fonlama turu sayÄ±sÄ± | Integer | 10 |
| 15 | `funding_option` | Fonlama seÃ§eneÄŸi | String | "Secondary market" |
| 16 | `last_funding_round` | Son fonlama turu tarihi | String | "Sep 14, 2023" |

**Toplam Veri AlanÄ±:** 16 farklÄ± parametre

---

## ğŸ”§ Gereksinimler ve Kurulum

### Sistem Gereksinimleri

- **Python:** 3.7 veya Ã¼zeri
- **Ä°ÅŸletim Sistemi:** Windows, macOS, Linux
- **Ä°nternet BaÄŸlantÄ±sÄ±:** Aktif internet baÄŸlantÄ±sÄ± gerekli

### Python Paketleri

Proje ÅŸu Python paketlerine ihtiyaÃ§ duyar:

```python
scrapy>=2.0.0          # Web scraping framework'Ã¼
requests                # HTTP istekleri iÃ§in (opsiyonel)
itemadapter            # Scrapy item adapter'Ä±
```

### Kurulum AdÄ±mlarÄ±

#### 1. Projeyi Ä°ndirin
```bash
cd /Users/faruk/Desktop/Tarvina/linkedin_scraping/LinkedIn-Company-Data-Scraping-System
```

#### 2. Python Sanal OrtamÄ± OluÅŸturun (Ã–nerilir)
```bash
python3 -m venv venv
source venv/bin/activate  # macOS/Linux iÃ§in
# veya
venv\Scripts\activate      # Windows iÃ§in
```

#### 3. Gerekli Paketleri YÃ¼kleyin
```bash
pip install scrapy requests itemadapter
```

#### 4. Proje KlasÃ¶rÃ¼ne Gidin
```bash
cd company_data_scraper
```

---

## ğŸš€ KullanÄ±m KÄ±lavuzu

### AdÄ±m 1: Åirket Dizini Verilerini Ã‡ekme

Ä°lk olarak, LinkedIn'deki tÃ¼m ÅŸirket isimlerini ve URL'lerini Ã§ekmeniz gerekir:

```bash
cd company_data_scraper
scrapy crawl linkedin_directory_scraper -O directorydata.json
```

**Ne Olur?**
- LinkedIn ÅŸirket dizini taranÄ±r
- A-Z harfleri ve "More" kategorisi iÃ§in tÃ¼m sayfalar ziyaret edilir
- Åirket isimleri ve URL'leri `directorydata.json` dosyasÄ±na kaydedilir
- Ä°ÅŸlem birkaÃ§ saat sÃ¼rebilir (200K+ ÅŸirket)

**Ã‡Ä±ktÄ±:** `directorydata.json` dosyasÄ± oluÅŸturulur

---

### AdÄ±m 2: Belirli Åirketlerin Profil Bilgilerini Ã‡ekme

#### 2.1 Åirket Ä°simlerini Belirleyin

`company_profile_scraper.py` dosyasÄ±nÄ± aÃ§Ä±n ve `desired_company_names` listesini dÃ¼zenleyin:

```python
desired_company_names = ["OpenAI", "Microsoft", "Google", "Apple"]  # Ä°stediÄŸiniz ÅŸirketleri ekleyin
```

**Ã–nemli:** Åirket isimlerinin yazÄ±mÄ±na dikkat edin! `directorydata.json` dosyasÄ±ndaki isimlerle tam olarak eÅŸleÅŸmelidir.

#### 2.2 Profil Verilerini Ã‡ekin

```bash
scrapy crawl company_profile_scraper -O company_profile.json
```

**Ne Olur?**
- `directorydata.json` dosyasÄ± okunur
- BelirttiÄŸiniz ÅŸirket isimleri aranÄ±r
- Bulunan ÅŸirketlerin LinkedIn URL'leri alÄ±nÄ±r
- Her ÅŸirket profil sayfasÄ± ziyaret edilir
- DetaylÄ± bilgiler Ã§Ä±karÄ±lÄ±r ve `company_profile.json` dosyasÄ±na kaydedilir

**Ã‡Ä±ktÄ±:** `company_profile.json` dosyasÄ± oluÅŸturulur

---

### Alternatif Ã‡Ä±ktÄ± FormatlarÄ±

Scrapy, farklÄ± formatlarda Ã§Ä±ktÄ± almanÄ±za izin verir:

```bash
# JSON formatÄ±nda
scrapy crawl company_profile_scraper -O company_profile.json

# CSV formatÄ±nda
scrapy crawl company_profile_scraper -O company_profile.csv

# XML formatÄ±nda
scrapy crawl company_profile_scraper -O company_profile.xml
```

---

## ğŸ§­ SektÃ¶r BazlÄ± Tek Pipeline KullanÄ±mÄ± (Root'tan)

Bu akÄ±ÅŸta **sektÃ¶r verilir**, sistem LinkedIn aramasÄ±ndan ÅŸirketleri bulur ve **aynÄ± koÅŸuda** ÅŸirket profil detaylarÄ±nÄ± Ã§ekip tek bir Ã§Ä±ktÄ±ya yazar.

### Ã‡alÄ±ÅŸtÄ±rma

Root dizinde:

```bash
python scrape_by_sector.py --sector "Technology"
```

Opsiyonel olarak arama sayfasÄ± sayÄ±sÄ±nÄ± sÄ±nÄ±rlamak iÃ§in:

```bash
python scrape_by_sector.py --sector "Technology" --max-pages 3
```

### Ã‡Ä±ktÄ±

Her sektÃ¶r iÃ§in ayrÄ± dosya Ã¼retilir:
- `technology_companies.json`
- `finance_companies.json`
- `healthcare_companies.json`

---

## ğŸ” Teknik Detaylar

### Scrapy AyarlarÄ± (`settings.py`)

```python
BOT_NAME = "company_data_scraper"
USER_AGENT = "Mozilla/5.0 (Linux; Android 11; Redmi Note 8 Pro) AppleWebKit/537.36..."
ROBOTSTXT_OBEY = False  # robots.txt kurallarÄ±nÄ± gÃ¶rmezden gel
FEED_EXPORT_ENCODING = "utf-8"  # TÃ¼rkÃ§e karakter desteÄŸi
```

**Ã–nemli Ayarlar:**
- **USER_AGENT:** TarayÄ±cÄ± kimliÄŸi (bot olarak algÄ±lanmamak iÃ§in)
- **ROBOTSTXT_OBEY:** False olarak ayarlanmÄ±ÅŸ (LinkedIn'in robots.txt kurallarÄ±nÄ± gÃ¶rmezden gelir)
- **FEED_EXPORT_ENCODING:** UTF-8 karakter kodlamasÄ±

### Google Cache KullanÄ±mÄ±

Proje, LinkedIn'in anti-bot korumasÄ±nÄ± aÅŸmak iÃ§in **Google Cache** kullanÄ±r:

```
Normal URL: https://www.linkedin.com/directory/companies
Cache URL:  https://webcache.googleusercontent.com/search?q=cache:https://www.linkedin.com/directory/companies
```

**AvantajlarÄ±:**
- LinkedIn'in doÄŸrudan eriÅŸim kÄ±sÄ±tlamalarÄ±nÄ± aÅŸar
- Daha az bot tespiti riski
- Daha stabil eriÅŸim

**DezavantajlarÄ±:**
- Veriler gÃ¼ncel olmayabilir (cache'lenmiÅŸ versiyonlar)
- Google Cache'in kendi kÄ±sÄ±tlamalarÄ± olabilir

### Veri Ã‡Ä±karma YÃ¶ntemleri

#### CSS SeÃ§icileri
```python
response.css('.top-card-layout__entity-info h1::text').get()
```

#### XPath SeÃ§icileri
```python
response.xpath('//h3[contains(@class, "top-card-layout__first-subline")]/span/following-sibling::text()').get()
```

#### Regex KullanÄ±mÄ±
```python
re.findall(r'\d{1,3}(?:,\d{3})*', text)  # SayÄ±larÄ± Ã§Ä±karmak iÃ§in
```

### Hata YÃ¶netimi

Proje, eksik veriler iÃ§in `try-except` bloklarÄ± kullanÄ±r:

```python
try:
    # Veri Ã§Ä±karma iÅŸlemi
except IndexError:
    print("Error: *****Skipped index, as some details are missing*********")
except Exception as e:
    print(f"Error occurred: {e}")
```

Eksik veriler iÃ§in `"not-found"` deÄŸeri kullanÄ±lÄ±r.

---

## âš ï¸ Ã–nemli Notlar ve SÄ±nÄ±rlamalar

### Yasal ve Etik UyarÄ±lar

1. **LinkedIn KullanÄ±m ÅartlarÄ±:**
   - LinkedIn'in Terms of Service'ini ihlal edebilir
   - Otomatik veri Ã§ekme LinkedIn tarafÄ±ndan yasaklanmÄ±ÅŸ olabilir
   - KullanÄ±mÄ±nÄ±zÄ±n sorumluluÄŸu size aittir

2. **Rate Limiting:**
   - LinkedIn, Ã§ok fazla istek yaparsanÄ±z IP adresinizi engelleyebilir
   - Ä°stekler arasÄ±nda gecikme eklemeniz Ã¶nerilir

3. **Veri KullanÄ±mÄ±:**
   - Ã‡ekilen verileri ticari amaÃ§larla kullanmadan Ã¶nce yasal danÄ±ÅŸmanlÄ±k alÄ±n
   - KiÅŸisel verilerin korunmasÄ± yasalarÄ±na (GDPR, KVKK) dikkat edin

### Teknik SÄ±nÄ±rlamalar

1. **LinkedIn HTML YapÄ±sÄ± DeÄŸiÅŸiklikleri:**
   - LinkedIn, sayfa yapÄ±sÄ±nÄ± deÄŸiÅŸtirebilir
   - CSS/XPath seÃ§icileri Ã§alÄ±ÅŸmayabilir
   - Kodun gÃ¼ncellenmesi gerekebilir

2. **Google Cache BaÄŸÄ±mlÄ±lÄ±ÄŸÄ±:**
   - Google Cache'e eriÅŸim kÄ±sÄ±tlanabilir
   - Cache'lenmiÅŸ veriler gÃ¼ncel olmayabilir

3. **Veri DoÄŸruluÄŸu:**
   - BazÄ± ÅŸirketler eksik bilgilere sahip olabilir
   - "not-found" deÄŸerleri gÃ¶rÃ¼lebilir
   - Verileri manuel olarak doÄŸrulamanÄ±z Ã¶nerilir

4. **Performans:**
   - Directory scraper uzun sÃ¼rebilir (saatler)
   - Ã‡ok sayÄ±da ÅŸirket iÃ§in profil scraper yavaÅŸ olabilir
   - Ä°nternet hÄ±zÄ±nÄ±za baÄŸlÄ±dÄ±r

### Ã–nerilen Ä°yileÅŸtirmeler

1. **Rate Limiting Ekleyin:**
```python
# settings.py'ye ekleyin
DOWNLOAD_DELAY = 2  # Ä°stekler arasÄ± 2 saniye bekle
RANDOMIZE_DOWNLOAD_DELAY = True  # Rastgele gecikme
```

2. **Proxy KullanÄ±mÄ±:**
   - IP engellemelerini Ã¶nlemek iÃ§in proxy rotasyonu ekleyin

3. **User-Agent Rotasyonu:**
   - FarklÄ± tarayÄ±cÄ± kimlikleri kullanÄ±n

4. **VeritabanÄ± Entegrasyonu:**
   - JSON yerine veritabanÄ±na kaydetme
   - Daha kolay sorgulama ve analiz

5. **Hata Loglama:**
   - DetaylÄ± log dosyalarÄ± oluÅŸturun
   - BaÅŸarÄ±sÄ±z istekleri kaydedin

---

## ğŸ“ Ã–rnek KullanÄ±m SenaryolarÄ±

### Senaryo 1: Tek Bir Åirket HakkÄ±nda Bilgi Toplama

```python
# company_profile_scraper.py iÃ§inde
desired_company_names = ["OpenAI"]
```

```bash
scrapy crawl company_profile_scraper -O openai_profile.json
```

### Senaryo 2: Belirli SektÃ¶rdeki Åirketleri Analiz Etme

1. Directory scraper'Ä± Ã§alÄ±ÅŸtÄ±rÄ±n
2. `directorydata.json` dosyasÄ±nÄ± aÃ§Ä±n
3. Ä°lgilendiÄŸiniz sektÃ¶rdeki ÅŸirketleri bulun
4. `desired_company_names` listesine ekleyin
5. Profile scraper'Ä± Ã§alÄ±ÅŸtÄ±rÄ±n

### Senaryo 3: Toplu Veri Analizi

1. TÃ¼m ÅŸirket dizinini Ã§ekin
2. Ä°stediÄŸiniz ÅŸirketleri seÃ§in
3. Profil verilerini Ã§ekin
4. JSON dosyasÄ±nÄ± pandas ile analiz edin:

```python
import pandas as pd
import json

with open('company_profile.json', 'r') as f:
    data = json.load(f)

df = pd.DataFrame(data)
print(df.describe())
print(df['industry'].value_counts())
```

---

## ğŸ› Sorun Giderme

### Sorun: "No company URLs found"

**Ã‡Ã¶zÃ¼m:**
- `directorydata.json` dosyasÄ±nÄ±n mevcut olduÄŸundan emin olun
- Åirket isimlerinin yazÄ±mÄ±nÄ± kontrol edin
- JSON dosyasÄ±nÄ±n formatÄ±nÄ± kontrol edin

### Sorun: "Error: JSON file not found"

**Ã‡Ã¶zÃ¼m:**
- Ã–nce directory scraper'Ä± Ã§alÄ±ÅŸtÄ±rÄ±n
- Dosya yolunun doÄŸru olduÄŸundan emin olun

### Sorun: Veriler Ã§ekilmiyor veya "not-found" geliyor

**Ã‡Ã¶zÃ¼m:**
- LinkedIn sayfa yapÄ±sÄ± deÄŸiÅŸmiÅŸ olabilir
- CSS/XPath seÃ§icilerini gÃ¼ncellemeniz gerekebilir
- Google Cache'e eriÅŸim sorunu olabilir

### Sorun: IP adresim engellendi

**Ã‡Ã¶zÃ¼m:**
- Ä°stekler arasÄ± gecikme ekleyin (`DOWNLOAD_DELAY`)
- Proxy kullanÄ±n
- FarklÄ± bir aÄŸdan deneyin

---

## ğŸ“š Ek Kaynaklar

- [Scrapy DokÃ¼mantasyonu](https://docs.scrapy.org/)
- [CSS SeÃ§icileri Rehberi](https://www.w3schools.com/cssref/css_selectors.asp)
- [XPath Rehberi](https://www.w3schools.com/xml/xpath_intro.asp)
- [LinkedIn Terms of Service](https://www.linkedin.com/legal/user-agreement)

---

## ğŸ“ Destek ve KatkÄ±da Bulunma

Bu proje aÃ§Ä±k kaynaklÄ±dÄ±r ve katkÄ±larÄ±nÄ±zÄ± bekler. SorunlarÄ±nÄ±z veya Ã¶nerileriniz iÃ§in:

1. GitHub Issues aÃ§Ä±n
2. Pull Request gÃ¶nderin
3. DokÃ¼mantasyonu iyileÅŸtirin

---

## ğŸ“„ Lisans

Proje lisans bilgileri iÃ§in `LICENSE` dosyasÄ±na bakÄ±n.

---

**Son GÃ¼ncelleme:** 2024
**Versiyon:** 1.0
**Dil:** Python 3.7+
**Framework:** Scrapy 2.0+

---

*Bu dokÃ¼mantasyon, projenin detaylÄ± analizi ve kullanÄ±m kÄ±lavuzunu iÃ§ermektedir. Teknik sorularÄ±nÄ±z iÃ§in Scrapy dokÃ¼mantasyonunu inceleyebilirsiniz.*
